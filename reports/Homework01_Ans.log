Traceback (most recent call last):
  File "c:\users\user\.conda\envs\tensorflow-gpu\lib\site-packages\jupyter_cache\executors\utils.py", line 51, in single_nb_execution
    executenb(
  File "c:\users\user\.conda\envs\tensorflow-gpu\lib\site-packages\nbclient\client.py", line 1112, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "c:\users\user\.conda\envs\tensorflow-gpu\lib\site-packages\nbclient\util.py", line 74, in wrapped
    return just_run(coro(*args, **kwargs))
  File "c:\users\user\.conda\envs\tensorflow-gpu\lib\site-packages\nbclient\util.py", line 53, in just_run
    return loop.run_until_complete(coro)
  File "c:\users\user\.conda\envs\tensorflow-gpu\lib\asyncio\base_events.py", line 616, in run_until_complete
    return future.result()
  File "c:\users\user\.conda\envs\tensorflow-gpu\lib\site-packages\nbclient\client.py", line 553, in async_execute
    await self.async_execute_cell(
  File "c:\users\user\.conda\envs\tensorflow-gpu\lib\site-packages\nbclient\client.py", line 857, in async_execute_cell
    self._check_raise_for_error(cell, exec_reply)
  File "c:\users\user\.conda\envs\tensorflow-gpu\lib\site-packages\nbclient\client.py", line 760, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import pandas as pd
import numpy as np
from sklearn import datasets     # ÂºïÁî® Scikit-Learn ‰∏≠ÁöÑ Â•ó‰ª∂ datasets
pd.set_option('display.float_format', lambda x: f'{x:.3}')           # ËΩâÊèõ 'ÁßëÂ≠∏Ë®òËôü' to 'ÊµÆÈªûÊï∏'


df = pd.read_csv('tips.csv')
print(df)

# 1. Dataset
X = df.drop('tip', axis=1)
# print(X.head())
y = df['tip']
# print(y.head())

# 2. Data clean
# 2-1. isna
print(df.isna().sum())

# 2-2. coding coulumn item
print(X['day'].unique())

gb = df.groupby(['day'])['tip'].mean()
print(gb)
import seaborn as sns
import matplotlib.pyplot as plt
sns.barplot(gb.index, gb.values)
plt.savefig('pic_18.png')
plt.show()

X['sex'].replace({'Female' : 0, 'Male' : 1}, inplace=True)
X['smoker'].replace({'Yes' : 0, 'No' : 1}, inplace=True)
X['day'].replace({'Thur' : 0, 'Fri' : 0, 'Sat' : 2, 'Sun' : 3}, inplace=True)
X['time'].replace({'Lunch' : 0, 'Dinner' : 1}, inplace=True)
# print(X)
# print(y)

# 3. Date Feturing

# 4. Split
from sklearn.model_selection import train_test_split as tts

# test_size=0.2 : Ê∏¨Ë©¶Áî®Ë≥áÊñôÁÇ∫ 20%
X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2)
print(X_train.shape, y_train.shape)
# ÂæóÂà∞ (195, 6) (195,)
print('------------------------------------------')


# 5. Define and train the LinearRegression model
from sklearn.linear_model import LinearRegression

clf = LinearRegression()
clf.fit(X_train, y_train)

print(f'score = {clf.score(X_test, y_test):.2}')

# È©óË≠âÁ≠îÊ°à
print(list(y_test))
b = [float(f'{i:.2}') for i in clf.predict(X_test)]
print(b)
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mFileNotFoundError[0m                         Traceback (most recent call last)
[1;32m<ipython-input-4-d8e379aadae6>[0m in [0;36m<module>[1;34m[0m
[0;32m      5[0m [1;33m[0m[0m
[0;32m      6[0m [1;33m[0m[0m
[1;32m----> 7[1;33m [0mdf[0m [1;33m=[0m [0mpd[0m[1;33m.[0m[0mread_csv[0m[1;33m([0m[1;34m'tips.csv'[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m      8[0m [0mprint[0m[1;33m([0m[0mdf[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0;32m      9[0m [1;33m[0m[0m

[1;32m~\.conda\envs\tensorflow-gpu\lib\site-packages\pandas\io\parsers.py[0m in [0;36mparser_f[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)[0m
[0;32m    674[0m         )
[0;32m    675[0m [1;33m[0m[0m
[1;32m--> 676[1;33m         [1;32mreturn[0m [0m_read[0m[1;33m([0m[0mfilepath_or_buffer[0m[1;33m,[0m [0mkwds[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    677[0m [1;33m[0m[0m
[0;32m    678[0m     [0mparser_f[0m[1;33m.[0m[0m__name__[0m [1;33m=[0m [0mname[0m[1;33m[0m[1;33m[0m[0m

[1;32m~\.conda\envs\tensorflow-gpu\lib\site-packages\pandas\io\parsers.py[0m in [0;36m_read[1;34m(filepath_or_buffer, kwds)[0m
[0;32m    446[0m [1;33m[0m[0m
[0;32m    447[0m     [1;31m# Create the parser.[0m[1;33m[0m[1;33m[0m[1;33m[0m[0m
[1;32m--> 448[1;33m     [0mparser[0m [1;33m=[0m [0mTextFileReader[0m[1;33m([0m[0mfp_or_buf[0m[1;33m,[0m [1;33m**[0m[0mkwds[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    449[0m [1;33m[0m[0m
[0;32m    450[0m     [1;32mif[0m [0mchunksize[0m [1;32mor[0m [0miterator[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m

[1;32m~\.conda\envs\tensorflow-gpu\lib\site-packages\pandas\io\parsers.py[0m in [0;36m__init__[1;34m(self, f, engine, **kwds)[0m
[0;32m    878[0m             [0mself[0m[1;33m.[0m[0moptions[0m[1;33m[[0m[1;34m"has_index_names"[0m[1;33m][0m [1;33m=[0m [0mkwds[0m[1;33m[[0m[1;34m"has_index_names"[0m[1;33m][0m[1;33m[0m[1;33m[0m[0m
[0;32m    879[0m [1;33m[0m[0m
[1;32m--> 880[1;33m         [0mself[0m[1;33m.[0m[0m_make_engine[0m[1;33m([0m[0mself[0m[1;33m.[0m[0mengine[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    881[0m [1;33m[0m[0m
[0;32m    882[0m     [1;32mdef[0m [0mclose[0m[1;33m([0m[0mself[0m[1;33m)[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m

[1;32m~\.conda\envs\tensorflow-gpu\lib\site-packages\pandas\io\parsers.py[0m in [0;36m_make_engine[1;34m(self, engine)[0m
[0;32m   1112[0m     [1;32mdef[0m [0m_make_engine[0m[1;33m([0m[0mself[0m[1;33m,[0m [0mengine[0m[1;33m=[0m[1;34m"c"[0m[1;33m)[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m   1113[0m         [1;32mif[0m [0mengine[0m [1;33m==[0m [1;34m"c"[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m-> 1114[1;33m             [0mself[0m[1;33m.[0m[0m_engine[0m [1;33m=[0m [0mCParserWrapper[0m[1;33m([0m[0mself[0m[1;33m.[0m[0mf[0m[1;33m,[0m [1;33m**[0m[0mself[0m[1;33m.[0m[0moptions[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m   1115[0m         [1;32melse[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m   1116[0m             [1;32mif[0m [0mengine[0m [1;33m==[0m [1;34m"python"[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m

[1;32m~\.conda\envs\tensorflow-gpu\lib\site-packages\pandas\io\parsers.py[0m in [0;36m__init__[1;34m(self, src, **kwds)[0m
[0;32m   1889[0m         [0mkwds[0m[1;33m[[0m[1;34m"usecols"[0m[1;33m][0m [1;33m=[0m [0mself[0m[1;33m.[0m[0musecols[0m[1;33m[0m[1;33m[0m[0m
[0;32m   1890[0m [1;33m[0m[0m
[1;32m-> 1891[1;33m         [0mself[0m[1;33m.[0m[0m_reader[0m [1;33m=[0m [0mparsers[0m[1;33m.[0m[0mTextReader[0m[1;33m([0m[0msrc[0m[1;33m,[0m [1;33m**[0m[0mkwds[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m   1892[0m         [0mself[0m[1;33m.[0m[0munnamed_cols[0m [1;33m=[0m [0mself[0m[1;33m.[0m[0m_reader[0m[1;33m.[0m[0munnamed_cols[0m[1;33m[0m[1;33m[0m[0m
[0;32m   1893[0m [1;33m[0m[0m

[1;32mpandas\_libs\parsers.pyx[0m in [0;36mpandas._libs.parsers.TextReader.__cinit__[1;34m()[0m

[1;32mpandas\_libs\parsers.pyx[0m in [0;36mpandas._libs.parsers.TextReader._setup_parser_source[1;34m()[0m

[1;31mFileNotFoundError[0m: [Errno 2] File tips.csv does not exist: 'tips.csv'
FileNotFoundError: [Errno 2] File tips.csv does not exist: 'tips.csv'

